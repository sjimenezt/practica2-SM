{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7801209a-0593-4e79-a57e-31acf9994db7",
   "metadata": {},
   "source": [
    "# Sesión 3 de SM: Introducción al análisis de audio con Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164f169f-d223-4279-9bd2-adacdd381045",
   "metadata": {},
   "source": [
    "## Condigurar el repositorio de GitHub, conda y JupyterLab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29638026-77f8-428e-a891-48c63607133e",
   "metadata": {},
   "source": [
    "* He creado un repositorio en github llamado practica2-SM y con el comando git clone lo clono como repostorio local para trabajar con el.\n",
    "* Con el comando conda create --name=audioConda creo mi entorno de conda y con conda env list compruebo que esta bien creado y lo activo con conda activate.\n",
    "* edito el .gitignore y añado la carpeta .ipynb_checkpoints/ para que la ignore.\n",
    "* Usamos el comando conda install -c conda-forge <package_name> para instalar Python 3.10, ipykernel y JupyterLab.\n",
    "* Añadimos el entorno de conda a los kernel de jupyterLab con python3 -m ipykernel install --user --name=<env_name>\n",
    "* Instalamos jupyterLab en el entorno de conda conda install -c conda-forge jupyterlab\n",
    "* Por ultimo Ejecutamos jupyterLab con el comando jupyter-lab y creamos un notebook vacio usando como kernel el entorno de conda \"audioconda\" creado anteriormente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b324584-50b5-40a4-a04d-026e5f767d20",
   "metadata": {},
   "source": [
    "## Análisis de audio con Python y jupyterLab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7277e5e-d7a0-4b85-97c4-8406f05a17be",
   "metadata": {},
   "source": [
    "### Importar librerias y modulos de python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692140a2-4f0e-47eb-b626-ceb1510ff6c7",
   "metadata": {},
   "source": [
    "Importamos las librerias y modulos que vamos a utilizar de la siguiente forma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d36c2ba-1e54-4a24-9011-ba6e6119383f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import librosa\n",
    "from scipy.io import wavfile\n",
    "import IPython\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt #incluimos esta libreria para poder crear las graficas en el dominio del tiempo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9cec54-ab01-4684-aac2-617144abacf4",
   "metadata": {},
   "source": [
    "### Especificamos los directorios de entrada salida"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0bdcb0-fbac-4a0a-b31a-d86202a37423",
   "metadata": {},
   "source": [
    "Aqui definiremos los directorios que ulitizaremos para almacenar los ficheros de audio con los que vamos a trabajar y donde almacenaremos los ficheros de audio que generaremos a lo largo de la práctica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dbfb24-e038-4fc7-a048-27c8da4b8b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#directorio que utilizaremos\n",
    "cwd = os.getcwd()\n",
    "entrada_audio = os.path.join(cwd, os.path.join('audio', '_entrada'))#guardamos en la variable el path de la carpeta _entrada\n",
    "salida_audio = os.path.join(cwd, os.path.join('audio', '_salida'))#guardamos en la variable el path de la carpeta _salida\n",
    "print(f'Directorio con los audios de entrada: {entrada_audio}')\n",
    "print(f'Directorio donde guardaremos los audios generados: {salida_audio}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b3b9e8-0765-4ed8-9bb5-b8fc79940dba",
   "metadata": {},
   "source": [
    "### Cargar del archivo de audio estereo y mostrar sus caracteristicas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7788e160-0d27-4767-9118-a23fa6f19a21",
   "metadata": {},
   "source": [
    "Utilizaremos un archivo de audio .wav en este caso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8dd0aa-4379-4998-b481-3d134780e2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cargamos el archivo de audio\n",
    "filename = os.path.join(entrada_audio, 'game_of_thrones.wav')\n",
    "#Mostrar informacion (sonido estéreo)\n",
    "sample_rate, audio_data = wavfile.read(filename)\n",
    "print(f'Frecuencia de muestreo (sample rate): {sample_rate/1000} kHz')\n",
    "print('Datos de audio (estereo):')\n",
    "print(f'- Tamaño:     {audio_data.shape}')#Mostramos el numero de filas y columnas de la matriz\n",
    "print(f'- 1º canal:   {audio_data[:10, 0]}...')#Mostramos los 10 primeros elementos del vector correspondiente al canal 0 \n",
    "print(f'- 2º canal:   {audio_data[:10, 1]}...')#Mostramos los 10 primeros elementos del vector correspondiente al canal 1\n",
    "print(f'- Resolucion: {type(audio_data[0,0])}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8bec5a-0542-4370-a502-295512a12b03",
   "metadata": {},
   "source": [
    "Vamos a escuchar el audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d24175-8c38-4a74-a818-4fbbc61c111d",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(audio_data.T, rate=sample_rate)# .T se pasa únicamente si es audio estéreo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c2e455-25f9-4697-aa0f-574cbced7d23",
   "metadata": {},
   "source": [
    "### Convertir el archivo de audio estereo a mono"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137958e6-b45c-474c-8412-88937faa6a2b",
   "metadata": {},
   "source": [
    "Vamos a calcular por simplificacion la media por canal para obtener un sonido mono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df20c4d-aebd-4f9c-b5d1-930295874c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos a mono mediante la media por canal (simplificacion).\n",
    "new_data_mono = audio_data.mean(axis=1)  #Hace la media de los dos canales de audio y convierte el audio de estereo a mono\n",
    "print('Nuevos datos de audio (mono):')\n",
    "print(f'- Nuevo tamaño: {new_data_mono.shape}')\n",
    "print(f'- Canal unico:  {new_data_mono[:5]}...')\n",
    "#Mantenemos la misma resolucion que en el audio estereo\n",
    "new_data_mono = new_data_mono.astype(np.int16)\n",
    "print(f'- Resolucion:   {type(new_data_mono[0])}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9b26ee-fedf-4171-9026-952e310d136c",
   "metadata": {},
   "source": [
    "Ahora guardaremos el archivo y lo reproduciremos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d5d529-d841-4ecd-8605-75e4eecfd103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el archivo mono a un fichero de tipo wav utilizando wavfile.write .\n",
    "wavfile.write(\n",
    "    filename=os.path.join(salida_audio, 'game_of_thrones_mono.wav'),#guardamos el archivo de audio convertido a mono en la carpeta _salida\n",
    "    rate=sample_rate,\n",
    "    data=new_data_mono\n",
    ")\n",
    "#Añadimos el widget para reproducir el audio\n",
    "IPython.display.Audio(new_data_mono, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4943b93f-6e48-4b18-a365-b4d48cf4ae8c",
   "metadata": {},
   "source": [
    "Mostramos el tamaño de ambos archivos pra ver la difrencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7ab155-591b-4220-ac84-3e60c580a9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -sh audio/_entrada/game_of_thrones.wav\n",
    "!ls -sh audio/_salida/game_of_thrones_mono.wav"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cda93fc-ca31-4f20-8a80-61fa756c997a",
   "metadata": {},
   "source": [
    "### Difrencia entre audio estéreo y mono "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7267d17b-c470-4b64-80b9-089735947d7e",
   "metadata": {},
   "source": [
    "El audio estereo tiene dos canales de audio distinto porque los que sale audio difrente, proporcionando una experiencia mas inversiva, mientras que el audio mono al ser la media de los dos canales estereos todo el sonido sale por el mismo canal, lo que produce que salga el mismo sonido por los dos altavoces de los auriculares."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdc53e0-f5a8-4d1e-9953-a66748d146b6",
   "metadata": {},
   "source": [
    "# Sesión 4 de SM: Procesamiento de audio con Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511960ea-9fe4-4475-b906-1b6fa5e49042",
   "metadata": {},
   "source": [
    "### Grafica en el dominio del tiempo para el audion mono y estereo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2406ad38-2814-4502-8453-b1edd86cf772",
   "metadata": {},
   "source": [
    "Creamos la funcion que nos permite generar la grafica a en el dominio del tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f32c87f-125b-4048-8047-9a507980c315",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion para mostrar la grafica en el domino del tiempo del audio mono\n",
    "def plot_mono_waveform(audio, sr, title):\n",
    "    time = np.arange(0, len(audio)) / sr #generamos el eje de tiempo en segundos\n",
    "    plt.figure(figsize =(12,6)) #se crea una nueva figura de tamaño 10x4\n",
    "    plt.plot(time, audio) #dibujamos la forma la onda de audio en el tiempo\n",
    "    plt.title(title) #nombre de la grafica\n",
    "    plt.xlabel(\"Tiempo (s)\") #etiqueta del eje x\n",
    "    plt.ylabel(\"Amplitud\") # etiqueta del eje y\n",
    "    plt.grid(True)\n",
    "    plt.show() #mostramos la grafica\n",
    "\n",
    "#funcion para mostrar la grafica en el dominio del tiempo del audio estereo\n",
    "def plot_stereo_waveform(audio_left, audio_right, sr, title):\n",
    "    time = np.arange(0, len(audio_left)) / sr #generamos el eje de tiempo en segundos\n",
    "    plt.figure(figsize =(12,6)) #se crea una nueva figura de tamaño 10x4\n",
    "    plt.plot(time, audio_left, label=\"canal izquierdo\") #dibujamos la forma la onda de audio en el tiempo del canal izquierdo\n",
    "    plt.plot(time, audio_right, label=\"canal derecho\") #dibujamos la forma la onda de audio en el tiempo del canal derecho\n",
    "    plt.title(title) #nombre de la grafica\n",
    "    plt.xlabel(\"Tiempo (s)\") #etiqueta del eje x\n",
    "    plt.ylabel(\"Amplitud\") # etiqueta del eje y \n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show() #mostramos la grafica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2bdc33-7e96-4c11-b6c3-35166b2647eb",
   "metadata": {},
   "source": [
    "Ahora se cargan los archivos de audio y se generan sus respectivas graficas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0895ffef-a360-4718-85c4-5743ca86de77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cargamos el archivo de audio mono\n",
    "filename_mono = os.path.join(salida_audio, 'game_of_thrones_mono.wav')\n",
    "sr_mono, audio_mono = wavfile.read(filename_mono)\n",
    "#Mostramos la grafica para el audio mono\n",
    "plot_mono_waveform(audio_mono, sr_mono, \"Audio Mono\")\n",
    "\n",
    "#cargamos el archivo de audio estereo\n",
    "filename_estereo = os.path.join(entrada_audio, 'game_of_thrones.wav')\n",
    "sr_stereo, audio_stereo = wavfile.read(filename_estereo)\n",
    "#extraemos los canales izquierdo y derecho del audio estereo\n",
    "audio_left = audio_stereo[:,0]\n",
    "audio_right = audio_stereo[:,1]\n",
    "#mostramos la grafica para el audio estereo\n",
    "plot_stereo_waveform(audio_left, audio_right, sr_stereo, \"Audio Estereo\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0a4a0a-52bf-43f0-a726-c1d82ab3767a",
   "metadata": {},
   "source": [
    "### Definiciones de frecuencia de muestreo, aliasing, profundidad de bits, ancho de banda y tasa de bits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be3f4ca-3ae7-4e16-8fae-b7064aa867a9",
   "metadata": {},
   "source": [
    "* Frecuencia de muestreo: Es la velocidad a la que se toman muestras del audio o tambien se puede definir como el numero de muestras que se toman por segundo, a mayor frecuencia de muestreo mayor sera la calidad de una muestra.\n",
    "* Aliasing: Es el nombre que se le da al efecto que provoca que dos señales continuas distintas se vuelvan indistinguibles al muestrearlas digitalmente a causa de una frecuencia de muestreo demasiado baja.\n",
    "* Profundidad de bits: Hace referencia a la cantidad de bits disponible para medir la onda sonora y para su posterior almacenamiento en bytes digitales.\n",
    "* Ancho de Banda: Se obtiene de la medicion conjunta de la profundidad de bits y la frecuencia de muestreo, por lo tanto el ancho de banda define la precision de nuestra señal digital con respecto a la grabacion original.\n",
    "* Tasa de bits: Es el cálculo matemático del tamaño de los archivos digitales en megabytes por segundo(Mbps), en base a esto se puede decir que determina el número de bits que el ordenador debe procesar por segundo para reproducir la grabación de audio digital de la forma prevista.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512edc68-d2ca-4e51-936c-dcf95eb82f19",
   "metadata": {},
   "source": [
    "### Aplicacion de la trasformada rapida de Fourier(FFT) para cambiar al dominio de la frecuencia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3535bdf0-d27b-4ab2-9e60-55310af0f14f",
   "metadata": {},
   "source": [
    "Caragamos el archivo de audio mono al que vamos a aplicar la FFT y llamamos a las distintas funciones para calcular la transformada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6fdb31-3611-4916-ab5c-aac81efa50d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr_mono, audio_data_mono = wavfile.read(filename=os.path.join(salida_audio, 'game_of_thrones_mono.wav'))\n",
    "\n",
    "n = len(audio_data_mono)\n",
    "Fs = sr_mono\n",
    "\n",
    "#Calculando la transformada rapida de Fourier\n",
    "ch_fourier = np.fft.fft(audio_data_mono)\n",
    "\n",
    "#solo observamos las frecuencias por debajo de Fs/2\n",
    "abs_ch_Fourier = np.absolute(ch_fourier[:n//2])\n",
    "\n",
    "#hacemos la grafica\n",
    "plt.figure(figsize =(8,6))\n",
    "plt.plot(np.linspace(0, Fs/2, n//2), abs_ch_Fourier)\n",
    "plt.ylabel('Amplitud', labelpad=10)\n",
    "plt.xlabel('$f$ (Hz)', labelpad=10)\n",
    "plt.show()\n",
    "                            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e27d6c-9a93-4088-9bfd-8bae054bff3e",
   "metadata": {},
   "source": [
    "La transformada de fourier es un aherramienta fundamental en el procesamiento de señales y en particular en el analisis de señales de audio. La Transformada de Fourier se utiliza para descomponer una señal en sus componentes de frecuencia, permitiendo así analizar su contenido espectral. Esto nos permite identificar qué frecuencias están presentes en la señal y con qué amplitud, lo que es crucial para su análisis y procesamiento. Tambien nos permite aplicar operaciones de procesamiento de señales específicas, como filtros, amplificación o atenuación selectiva de ciertas frecuencias, modificación del espectro de frecuencia para efectos de audio, entre otros. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52b8cd6-be47-4882-b5db-9f63f98c31ac",
   "metadata": {},
   "source": [
    "### Calculo de energia del espectrograma y la frecuencia de corte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa815930-7a92-4578-ae4f-6908487559ce",
   "metadata": {},
   "source": [
    "Ahora vamos a definir una frecuencia umbral $f_0$ por la que cortar el espectro, es decir, solo nos quedaremos con aquellas frecuencias que esten por debajo de este valor para el archivo de audio comprimido.\n",
    "\n",
    "El parametro epsilon reoresenta la parte de la energia del espectro que no conservaremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042580a9-e537-452d-b109-f6d7b2d53642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos diferentes epsilons.\n",
    "eps = [1e-5, .02, .041, .063, .086, .101, .123]\n",
    "\n",
    "#seleccionamos un valor de la lista de epsilons\n",
    "eps = eps[0]\n",
    "print(f'Epsilon: {eps}')\n",
    "\n",
    "# Calculamos el valor de corte para la energia del espectro \n",
    "thr_spec_energy = (1 - eps) * np.sum(abs_ch_Fourier)\n",
    "print(f'Valor de corte para la energia del espectro: {thr_spec_energy}')\n",
    "\n",
    "# calculamos la integral de la frecuencia que es igual a la energia del espectro.\n",
    "spec_energy = np.cumsum(abs_ch_Fourier)\n",
    "\n",
    "# Mascara booleana que compara el valor de corte con la energia del espectro e indica que frecuencias deben ser eliminadas\n",
    "frequencies_to_remove = thr_spec_energy < spec_energy  \n",
    "print(f'Mascara: {frequencies_to_remove}')\n",
    "\n",
    "# Calculamos la frecuencia de corte f0 en Hz mltiplicando la cantidad de frecuencias que deben ser eliminadas por el espacio de frecuencias y normalizando segun la longitud de la señal\n",
    "f0 = (len(frequencies_to_remove) - np.sum(frequencies_to_remove)) * (Fs/2) / (n//2) \n",
    "print(f'Frecuencia de corte f0 (Hz): {int(f0)}')\n",
    "\n",
    "# Generamos la grafica.\n",
    "plt.figure(figsize =(8,6))\n",
    "plt.axvline(f0, color='r')\n",
    "plt.plot(np.linspace(0, Fs/2, n//2), abs_ch_Fourier)\n",
    "plt.ylabel('Amplitud')\n",
    "plt.xlabel('$f$ (Hz)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13490c3d-066f-420e-828a-3ce487a88247",
   "metadata": {},
   "source": [
    "Hemos usado el valor Epsilon: 1e-05 para reducir el tamaño del espectro dejando sin utilizar las frecuencias a partir de la frecuencia de corte f0 (Hz): 22008 y por lo tanto reduciendo el tamaño del archivo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaee0ce-8f7d-4fc2-b3e8-36af0de0c3f9",
   "metadata": {},
   "source": [
    "### Compresion de la onda aplicando downsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7505db-5c30-4d84-b561-2b791e8e1a9a",
   "metadata": {},
   "source": [
    "Vamos a proceder a reducir el tamaño del audio mono aplicando downsampling donde el factor de downsampling que vamos a utilizar se obtiene a partir de la frecuencia de corte anteriormente calculada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c54ad50-fc2d-4816-86ba-813213c4ec4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_compressed_file = \"game_of_thrones_mono_compressed.wav\"\n",
    "\n",
    "# Calculamos el factor D de downsampling dividiendo la frecuencia de muestreo entre la frecuencia de corte\n",
    "D = int(Fs / f0)\n",
    "print(f'Factor de downsampling: {D}')\n",
    "\n",
    "# Obtenemos los nuevos datos \n",
    "new_data = audio_data_mono[::D]\n",
    "\n",
    "# Escribimos los datos a un archivo de tipo wav.\n",
    "wavfile.write(\n",
    "    filename=os.path.join(salida_audio, wav_compressed_file),\n",
    "    rate=int(Fs/D),\n",
    "    data=new_data\n",
    ")\n",
    "\n",
    "#Cargamos el nuevo archivo\n",
    "new_sample_rate, new_audio_data = wavfile.read(filename=os.path.join(salida_audio, wav_compressed_file))\n",
    "old_sample_rate, old_audio_data = wavfile.read(os.path.join(salida_audio, 'game_of_thrones_mono.wav'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b7c2c1-4b59-44ef-8849-275c26114d5e",
   "metadata": {},
   "source": [
    "### Espectrograma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd91acb-36a3-4e50-a04b-7ca69c7d8a10",
   "metadata": {},
   "source": [
    "Aqui realizaremos el espectrograma de ambas ondas para ver las difrencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393be398-d29f-44af-a636-5c52b2471a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
    "\n",
    "Pxx, freqs, bins, im = ax[0].specgram(old_audio_data, NFFT=1024, Fs=old_sample_rate, noverlap=512)\n",
    "ax[0].set_title('Espectograma del audio original')\n",
    "ax[0].set_ylabel('Frecuencia (Hz)')\n",
    "ax[0].grid(True)\n",
    "\n",
    "Pxx, freqs, bins, im = ax[1].specgram(new_audio_data, NFFT=1024, Fs=new_sample_rate, noverlap=512)\n",
    "ax[1].set_title('Espectrograma del audio reducido/comprimido')\n",
    "ax[1].set_xlabel('Tiempo (s)')\n",
    "ax[1].set_ylabel('Frecuencia (Hz)')\n",
    "ax[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077499c5-f3ed-49c0-92e1-d75fc115a5a9",
   "metadata": {},
   "source": [
    "Se puede apreciar como la resolucion se ha reducido, aunque en ciertas secciones de la onda se siguen apreciando caracteristicas similares."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4f5236-93ff-4c40-ab68-cf7c2d9f828c",
   "metadata": {},
   "source": [
    "Vamos a escuchar las dos pistas de audio, la comprimida y la original para compararlas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979ebe0c-5df5-4fae-8bf3-1d9148427988",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(new_audio_data, rate=new_sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91cf312-0d9b-40da-b28e-fb335d6f8029",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(old_audio_data, rate=old_sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad980c3-7c13-4593-a329-d97cc833043a",
   "metadata": {},
   "source": [
    "Se puede apreciar claramente que en la pista comprimida los instrumentos que suenan de fondo en la melodia dejan de oirse bien"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e95956-22a9-4b93-892e-ab4d26910047",
   "metadata": {},
   "source": [
    "Despues de la compresion como se puede comprobar el tamaño es menor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262a9055-3a74-4e9a-8734-60d958933b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -sh audio/_salida/game_of_thrones_mono.wav\n",
    "!ls -sh audio/_salida/game_of_thrones_mono_compressed.wav"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audioconda",
   "language": "python",
   "name": "audioconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
